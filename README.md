# Customer Churn Prediction

## ğŸ“Œ Project Overview  

This project focuses on predicting **customer churn** for a telecommunications provider. The goal is to **identify customers at risk of leaving** so the company can offer them promotional incentives and improve retention.  

The dataset includes information on **customer contracts, personal details, internet and phone services, and payment methods**. Using **machine learning models**, we aim to uncover patterns in customer behaviour and provide actionable insights.  

---

## ğŸ¢ Business Context  

The telecom company provides **landline telephony and internet services**, offering both DSL and fiber optic connections. Additional services include:  

- **Internet security** (*DeviceProtection*, *OnlineSecurity*)  
- **Technical support** (*TechSupport*)  
- **Cloud storage** (*OnlineBackup*)  
- **Entertainment** (*StreamingTV*, *StreamingMovies*)  

Customers can choose between **monthly, 1-year, or 2-year contracts** with different payment methods. The challenge is to analyze **which factors contribute to customer churn** and build a reliable predictive model.  

---

## ğŸ“Š Dataset  

The dataset consists of **four CSV files**, each containing different aspects of customer data:  

- `contract.csv` â€“ Contract details (start & end dates, payment type, etc.)  
- `personal.csv` â€“ Customer demographics  
- `internet.csv` â€“ Internet service details  
- `phone.csv` â€“ Telephony service details  

All files are linked by a unique **`customerID`**, and the churn status is determined by **contract end dates**.  

---

## ğŸš€ Approach  

### **1ï¸âƒ£ Data Preparation**  
âœ” Merged all datasets into a **single DataFrame**  
âœ” Standardized column names & adjusted data types  
âœ” Converted categorical variables into numerical features  
âœ” Handled missing values using **IterativeImputer**  

### **2ï¸âƒ£ Exploratory Data Analysis (EDA)**  
âœ” Identified key churn indicators  
âœ” Created new features (e.g., **contract duration**)  
âœ” Visualized **correlations & customer trends**  

### **3ï¸âƒ£ Model Training & Evaluation**  
âœ” Split data into **training (75%) and testing (25%)** sets  
âœ” Trained **Random Forest, CatBoost, and LightGBM** models  
âœ” Tuned hyperparameters using **GridSearchCV**  
âœ” Evaluated models using **AUC-ROC & Accuracy**  

---

## ğŸ† Model Results  

| Model           | AUC-ROC | Accuracy |
|----------------|---------|----------|
| **Random Forest** | 0.86 | 0.80 |
| **CatBoost** | 0.86 | 0.74 |
| **LightGBM** | 0.86 | 0.80 |

ğŸ’¡ **Why LightGBM?**  
- **Same AUC-ROC as other models**, but more computationally efficient  
- **Handles large datasets well** and is faster than Random Forest  
- **Balances performance & scalability**, making it the best choice  

---

## ğŸ”‘ Key Insights  

- **Who is most likely to churn?**  
  âœ… **Senior citizens (83.7%)**  
  âœ… **Customers with month-to-month contracts (55%)**  
  âœ… **Users without additional services (51-71%)**  

- **Contract length matters** â€“ shorter contracts (â‰¤ 10 months) have a higher churn rate  
- **Additional services reduce churn** â€“ customers with **OnlineSecurity, TechSupport, or StreamingTV** are more likely to stay  

---

## ğŸ›  Tech Stack  

- **Programming**: Python (`pandas`, `numpy`, `scikit-learn`)  
- **Machine Learning**: `RandomForestClassifier`, `GradientBoostingClassifier`, `CatBoostClassifier`, `LightGBM`  
- **Feature Engineering**: `IterativeImputer`, `GridSearchCV`  
- **Visualization**: `matplotlib`, `seaborn`  

---

## ğŸ¤ Contributions & Feedback  

If you have suggestions or improvements, feel free to reach out!  

ğŸ“© Contact: ofellipegaio@gmail.com | LinkedIn: https://www.linkedin.com/in/fellipegaio  
